{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models' predictions evaluation\n",
    "\n",
    "**NOTEBOOK GOAL**: Evaluate the predicted NumberOfSales values.\n",
    "\n",
    "\n",
    "Compared predictions:\n",
    "\n",
    "- **1_RFR** - Notebook 5.3 Random forrest\n",
    "- **2_XGB** - Notebook 6.4 XGBoost\n",
    "- **3_AVG** - Notebook 7.0 AVG Monthly average\n",
    "- **4_ENS_AVG** - Notebook 8.0 Ensamble by averaging all the previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_man import *\n",
    "import collections\n",
    "\n",
    "from BIP import get_BIP_error, apply_BIP_submission_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load predicted tests\n",
    "\n",
    "**NOTE** If you cannot load the followig datasets, please go to the corresponding notebook and run it to generate the related dataset file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict = collections.OrderedDict()\n",
    "# the following dataset will be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict['RFR'] = pd.read_csv('./dataset/test_m12_53_RFR_on_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict['XGB'] = pd.read_csv('./dataset/test_m12_64_Model_XGBoost_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict['AVG'] = pd.read_csv('./dataset/test_m12_70_Model_monthly_average.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the apply_BIP_submission_format to all the dataframes\n",
    "for mdl_lbl, df in dfs_dict.items():\n",
    "    dfs_dict[mdl_lbl] = apply_BIP_submission_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following dataset is already in the BIP submission format\n",
    "dfs_dict['ENS_AVG'] = pd.read_csv('./dataset/test_m12_82_Ensemble_average.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **[EVS] Explained Variance Score**  [(reference)](http://scikit-learn.org/stable/modules/model_evaluation.html#explained-variance-score)\n",
    "\n",
    "    The mean_absolute_error function computes mean absolute error, a risk metric corresponding to the expected value of the absolute error loss or l1-norm loss.\n",
    "    \n",
    "    $$ \\texttt{explained__variance}(y, \\hat{y}) = 1 - \\frac{Var\\{ y - \\hat{y}\\}}{Var\\{y\\}} $$\n",
    "    \n",
    "    The best possible score is 1.0, lower values are worse.\n",
    "    \n",
    "2. **[MAE] Mean absolute error**  [(reference)](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error)\n",
    "\n",
    "    The mean_squared_error function computes mean square error, a risk metric corresponding to the expected value of the squared (quadratic) error or loss.\n",
    "   \n",
    "    $$ \\text{MAE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}-1} \\left| y_i - \\hat{y}_i \\right| $$\n",
    "    \n",
    "3. **[MSE] Mean squared error**  [(reference)](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error)\n",
    "\n",
    "    The mean_squared_error function computes mean square error, a risk metric corresponding to the expected value of the squared (quadratic) error or loss.\n",
    "    \n",
    "    $$ \\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2 $$\n",
    "    \n",
    "4. **[RMSE] Root mean squared error**\n",
    "\n",
    "    $$ \\text{RMSE}(y, \\hat{y}) = \\sqrt{\\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\hat{y}_i)^2} $$\n",
    "    \n",
    "5. **[MSLE] Mean squared logarithmic error**  [(reference)](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-logarithmic-error)\n",
    "    \n",
    "    The mean_squared_log_error function computes a risk metric corresponding to the expected value of the squared logarithmic (quadratic) error or loss.\n",
    "    \n",
    "    $$ \\text{MSLE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} - 1} (\\log_e (1 + y_i) - \\log_e (1 + \\hat{y}_i) )^2 $$\n",
    "    \n",
    "    Where log_e (x) means the natural logarithm of x. This metric is best to use when targets having exponential growth, such as population counts, average sales of a commodity over a span of years etc. Note that this metric penalizes an under-predicted estimate greater than an over-predicted estimate.\n",
    "\n",
    "6. **[MedAE] Median absolute error**  [(reference)](http://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error)\n",
    "\n",
    "    The median_absolute_error is particularly interesting because it is robust to outliers. The loss is calculated by taking the median of all absolute differences between the target and the prediction.\n",
    "    \n",
    "    $$ \\text{MedAE}(y, \\hat{y}) = \\text{median}(\\mid y_1 - \\hat{y}_1 \\mid, \\ldots, \\mid y_n - \\hat{y}_n \\mid)$$\n",
    "    \n",
    "7. **[R²] R²score, the coefficient of determination**  [(reference)](http://scikit-learn.org/stable/modules/model_evaluation.html#r2-score-the-coefficient-of-determination)\n",
    "\n",
    "    The r2_score function computes R², the coefficient of determination. It provides a measure of how well future samples are likely to be predicted by the model. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "    \n",
    "    $$ R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=0}^{n_{\\text{samples}} - 1} (y_i - \\hat{y}_i)^2}{\\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\bar{y})^2}$$\n",
    "    \n",
    "    where\n",
    "    \n",
    "    $$ \\bar{y} =  \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}} - 1} y_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoreID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Target</th>\n",
       "      <th>NumberOfSales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>182917</td>\n",
       "      <td>201451.830901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>166161</td>\n",
       "      <td>184721.490504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>95745</td>\n",
       "      <td>83185.502132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2</td>\n",
       "      <td>88423</td>\n",
       "      <td>72102.648063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>121995</td>\n",
       "      <td>134334.706754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StoreID  Month  Target  NumberOfSales\n",
       "0     1000      1  182917  201451.830901\n",
       "1     1000      2  166161  184721.490504\n",
       "2     1001      1   95745   83185.502132\n",
       "3     1001      2   88423   72102.648063\n",
       "4     1002      1  121995  134334.706754"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfs_dict.values())[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "def print_regr_stats(df):\n",
    "    y_true = df['Target']\n",
    "    y_pred = df['NumberOfSales']\n",
    "    \n",
    "    stats = collections.OrderedDict()\n",
    "    stats['EVS']   = metrics.explained_variance_score(y_true, y_pred)\n",
    "    stats['MAE']   = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    stats['MSE']   = metrics.mean_squared_error(y_true, y_pred)\n",
    "    stats['RMSE']  = sqrt(stats['MSE'])\n",
    "    stats['MSLE']  = metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    stats['MedAE'] = metrics.median_absolute_error(y_true, y_pred)\n",
    "    stats['R2']    = metrics.r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(\"Explained Variance Score               [EVS] \", stats['EVS'])\n",
    "    print(\"Mean absolute error                    [MAE] \", stats['MAE'])\n",
    "    print(\"Mean squared error                     [MSE] \", stats['MSE'])\n",
    "    print(\"Root mean squared error               [RMSE] \", stats['RMSE'])\n",
    "    print(\"Mean squared logarithmic error        [MSLE] \", stats['MSLE'])\n",
    "    print(\"Median absolute error (reference)    [MedAE] \", stats['MedAE'])\n",
    "    print(\"R²score, coefficient of determination   [R²] \", stats['R2'])\n",
    "    \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................ RFR................................\n",
      "Explained Variance Score               [EVS]  0.9516157191345931\n",
      "Mean absolute error                    [MAE]  8403.387817765266\n",
      "Mean squared error                     [MSE]  130439386.0449889\n",
      "Root mean squared error               [RMSE]  11421.006349923324\n",
      "Mean squared logarithmic error        [MSLE]  0.00879432389306739\n",
      "Median absolute error (reference)    [MedAE]  6596.779882267692\n",
      "R²score, coefficient of determination   [R²]  0.9266278413635942\n",
      "\n",
      "\n",
      "................................ XGB................................\n",
      "Explained Variance Score               [EVS]  0.9554457225986508\n",
      "Mean absolute error                    [MAE]  6066.938750547397\n",
      "Mean squared error                     [MSE]  79212072.19523914\n",
      "Root mean squared error               [RMSE]  8900.116414701502\n",
      "Mean squared logarithmic error        [MSLE]  0.005160802533279368\n",
      "Median absolute error (reference)    [MedAE]  4035.7363999999943\n",
      "R²score, coefficient of determination   [R²]  0.9554432069695348\n",
      "\n",
      "\n",
      "................................ AVG................................\n",
      "Explained Variance Score               [EVS]  0.9447316764119325\n",
      "Mean absolute error                    [MAE]  6572.52946599536\n",
      "Mean squared error                     [MSE]  102904427.66533032\n",
      "Root mean squared error               [RMSE]  10144.181961367329\n",
      "Mean squared logarithmic error        [MSLE]  0.00711851471802916\n",
      "Median absolute error (reference)    [MedAE]  4544.63999999997\n",
      "R²score, coefficient of determination   [R²]  0.9421162562935934\n",
      "\n",
      "\n",
      "................................ ENS_AVG................................\n",
      "Explained Variance Score               [EVS]  0.9575541805029459\n",
      "Mean absolute error                    [MAE]  5662.949397176942\n",
      "Mean squared error                     [MSE]  77785489.36514951\n",
      "Root mean squared error               [RMSE]  8819.60823195393\n",
      "Mean squared logarithmic error        [MSLE]  0.005285724913816293\n",
      "Median absolute error (reference)    [MedAE]  3543.852302309104\n",
      "R²score, coefficient of determination   [R²]  0.9562456598550552\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "STATISTICS COMPARISON\n",
      "\n",
      "EVS\n",
      "[(0, ('AVG', 0.9447316764119325)),\n",
      " (1, ('RFR', 0.9516157191345931)),\n",
      " (2, ('XGB', 0.9554457225986508)),\n",
      " (3, ('ENS_AVG', 0.9575541805029459))]\n",
      "MAE\n",
      "[(0, ('ENS_AVG', 5662.949397176942)),\n",
      " (1, ('XGB', 6066.938750547397)),\n",
      " (2, ('AVG', 6572.52946599536)),\n",
      " (3, ('RFR', 8403.387817765266))]\n",
      "MSE\n",
      "[(0, ('ENS_AVG', 77785489.36514951)),\n",
      " (1, ('XGB', 79212072.19523914)),\n",
      " (2, ('AVG', 102904427.66533032)),\n",
      " (3, ('RFR', 130439386.0449889))]\n",
      "RMSE\n",
      "[(0, ('ENS_AVG', 8819.60823195393)),\n",
      " (1, ('XGB', 8900.116414701502)),\n",
      " (2, ('AVG', 10144.181961367329)),\n",
      " (3, ('RFR', 11421.006349923324))]\n",
      "MSLE\n",
      "[(0, ('XGB', 0.005160802533279368)),\n",
      " (1, ('ENS_AVG', 0.005285724913816293)),\n",
      " (2, ('AVG', 0.00711851471802916)),\n",
      " (3, ('RFR', 0.00879432389306739))]\n",
      "MedAE\n",
      "[(0, ('ENS_AVG', 3543.852302309104)),\n",
      " (1, ('XGB', 4035.7363999999943)),\n",
      " (2, ('AVG', 4544.63999999997)),\n",
      " (3, ('RFR', 6596.779882267692))]\n",
      "R2\n",
      "[(0, ('RFR', 0.9266278413635942)),\n",
      " (1, ('AVG', 0.9421162562935934)),\n",
      " (2, ('XGB', 0.9554432069695348)),\n",
      " (3, ('ENS_AVG', 0.9562456598550552))]\n"
     ]
    }
   ],
   "source": [
    "models_stats = collections.OrderedDict([(k, []) for k in ['EVS','MAE', 'MSE', 'RMSE', 'MSLE', 'MedAE', 'R2']])\n",
    "\n",
    "\n",
    "for mdl_lbl, df in dfs_dict.items():\n",
    "    print('................................ ' + mdl_lbl + '................................')\n",
    "    stats = print_regr_stats(df)\n",
    "    \n",
    "    # add the model statistics to the main index\n",
    "    for name, val in stats.items():\n",
    "        models_stats[name].append((mdl_lbl, val))\n",
    "        \n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "print(\"\\n\\nSTATISTICS COMPARISON\\n\")\n",
    "\n",
    "for name, l in models_stats.items():\n",
    "    print(name)\n",
    "    pprint(list(enumerate(sorted(l, key=lambda tup: tup[1]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIP error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................ RFR................................\n",
      "BIP total error: 0.06939371779958461\n",
      "\n",
      "\n",
      "................................ XGB................................\n",
      "BIP total error: 0.04913953326583034\n",
      "\n",
      "\n",
      "................................ AVG................................\n",
      "BIP total error: 0.05346477095060351\n",
      "\n",
      "\n",
      "................................ ENS_AVG................................\n",
      "BIP total error: 0.0454826943863305\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mdl_lbl, df in dfs_dict.items():\n",
    "    print('................................ ' + mdl_lbl + '................................')\n",
    "    get_BIP_error(df, already_BIP_format=True)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
